{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pycodestyle_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext pycodestyle_magic\n"
     ]
    }
   ],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%flake8_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import gc\n",
    "from time import time\n",
    "import datetime\n",
    "import multiprocessing\n",
    "import warnings\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from reduce_mem_usage import reduce_mem_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train_w_fe.csv')\n",
    "test = pd.read_csv('input/test_w_fe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove some cols and split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-31 23:58:51\n",
      "2018-07-01 00:00:24\n"
     ]
    }
   ],
   "source": [
    "rm_cols = [\n",
    "    'TransactionID', 'TransactionDT',  # These columns are pure noise right now\n",
    "    TARGET,                            # Not target in features))\n",
    "    'uid', 'uid2', 'uid3',             # Our new client uID -> very noisy data\n",
    "    'bank_type',                       # Victims bank could differ by time\n",
    "    'DT', 'DT_M', 'DT_W', 'DT_D',      # Temporary Variables\n",
    "    'DT_hour', 'DT_day_week', 'DT_day',\n",
    "    'DT_D_total', 'DT_W_total', 'DT_M_total',\n",
    "    'id_30', 'id_31', 'id_33',\n",
    "]\n",
    "\n",
    "features_columns = [col for col in list(train) if col not in rm_cols]\n",
    "\n",
    "# The June month drops entirely\n",
    "train['random_noise'] = np.random.randn(len(train))\n",
    "print(train['DT'].max())\n",
    "print(test['DT'].min())\n",
    "# So we need to get rid of April and keep May as validation set\n",
    "X_train = train[train['DT'] <= '2018-03-31']\n",
    "y_train = X_train[TARGET]\n",
    "X_train = X_train[features_columns]\n",
    "X_valid = train[(train['DT'] >= '2018-05-01')]\n",
    "y_valid = X_valid[TARGET]\n",
    "X_valid = X_valid[features_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions_lgb(tr_df, tt_df, features_columns,\n",
    "                         target, lgb_params, NFOLDS=2):\n",
    "    folds = KFold(n_splits=NFOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "    X, y = tr_df[features_columns], tr_df[target]\n",
    "    P = tt_df[features_columns]\n",
    "\n",
    "    predictions = np.zeros(len(sub))\n",
    "    permut_imp_allfolds = []\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "        print('Fold:', fold_)\n",
    "        tr_x, tr_y = X.iloc[trn_idx, :], y[trn_idx]\n",
    "        vl_x, vl_y = X.iloc[val_idx, :], y[val_idx]\n",
    "\n",
    "        print(len(tr_x), len(vl_x))\n",
    "        tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "\n",
    "        vl_data = lgb.Dataset(vl_x, label=vl_y)\n",
    "\n",
    "        estimator = lgb.train(\n",
    "            lgb_params,\n",
    "            tr_data,\n",
    "            valid_sets=[tr_data, vl_data],\n",
    "            verbose_eval=200,\n",
    "        )\n",
    "\n",
    "        pp_p = estimator.predict(P)\n",
    "        predictions += pp_p/NFOLDS\n",
    "\n",
    "        permut_imp_fold = permut_imp(estimator, vl_x, vl_y)\n",
    "        permut_imp_allfolds.append(permut_imp_fold)\n",
    "\n",
    "        del tr_x, tr_y, vl_x, vl_y, tr_data, vl_data\n",
    "        gc.collect()\n",
    "\n",
    "    tt_df['prediction'] = predictions\n",
    "\n",
    "    return estimator, tt_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns = [col for col in list(train) if col not in rm_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "506177 84363\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.960897\tvalid_1's auc: 0.94032\n",
      "[400]\ttraining's auc: 0.984326\tvalid_1's auc: 0.955628\n",
      "[600]\ttraining's auc: 0.994611\tvalid_1's auc: 0.965867\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 496,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':800,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':-1,\n",
    "                    'seed': 24,\n",
    "                    'early_stopping_rounds':100, \n",
    "                } \n",
    "\n",
    "lgb_params['learning_rate'] = 0.005\n",
    "lgb_params['n_estimators'] = 1800\n",
    "lgb_params['early_stopping_rounds'] = 100    \n",
    "clf, test_predictions = make_predictions_lgb(train, test,\n",
    "                                             features_columns,\n",
    "                                             TARGET, lgb_params,\n",
    "                                             NFOLDS=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions['isFraud'] = test_predictions['prediction']\n",
    "test_predictions['TransactionID']=test['TransactionID']\n",
    "test_predictions[['TransactionID','isFraud']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
