{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from time import time\n",
    "import datetime\n",
    "from reduce_mem_usage import reduce_mem_usage\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "warnings.simplefilter('ignore')\n",
    "sns.set()\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['/input/test_identity.csv', \n",
    "         '/input/test_transaction.csv',\n",
    "         '/input/train_identity.csv',\n",
    "         '/input/train_transaction.csv',\n",
    "         '/input/sample_submission.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction = pd.read_csv('input/train_transaction.csv', index_col='TransactionID')\n",
    "test_transaction = pd.read_csv('input/test_transaction.csv', index_col='TransactionID')\n",
    "\n",
    "train_identity = pd.read_csv('input/train_identity.csv', index_col='TransactionID')\n",
    "test_identity = pd.read_csv('input/test_identity.csv', index_col='TransactionID')\n",
    "\n",
    "sample_submission = pd.read_csv('input/sample_submission.csv', index_col='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n",
    "test = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')\n",
    "\n",
    "del test_identity, test_transaction, train_identity, train_transaction\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train=reduce_mem_usage(train)\n",
    "# test=reduce_mem_usage(test)\n",
    "\n",
    "# double check no problems \n",
    "# train2 = reduce_mem_usage(train)\n",
    "# numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "# for col in train.columns:\n",
    "#     if train[col].dtype in numerics:\n",
    "#         if (abs(train2[col] - train[col]) > 0.00001).any():\n",
    "#             print(col)\n",
    "            \n",
    "# (train['TransactionAmt'] - train2['TransactionAmt'] == 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')\n",
    "for df in [train, test]:\n",
    "    # Temporary\n",
    "    df['DT'] = df['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
    "    df['DT_M'] = (df['DT'].dt.year-2017)*12 + df['DT'].dt.month\n",
    "    df['DT_W'] = (df['DT'].dt.year-2017)*52 + df['DT'].dt.weekofyear\n",
    "    df['DT_D'] = (df['DT'].dt.year-2017)*365 + df['DT'].dt.dayofyear\n",
    "    \n",
    "    df['DT_hour'] = df['DT'].dt.hour\n",
    "    df['DT_day_week'] = df['DT'].dt.dayofweek\n",
    "    df['DT_day'] = df['DT'].dt.day\n",
    "\n",
    "## Test different options for this\n",
    "## Test different options for this\n",
    "    # D9 column\n",
    "    df['D9_isnull'] = np.where(df['D9'].isna(),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test different options for this\n",
    "## Test different options for this\n",
    "for feature in ['card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'id_36']:\n",
    "    train[feature + '_count_full'] = train[feature].map(pd.concat([train[feature], test[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "    test[feature + '_count_full'] = test[feature].map(pd.concat([train[feature], test[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "# Encoding - count encoding separately for train and test\n",
    "for feature in ['id_01', 'id_31', 'id_33', 'id_36']:\n",
    "    train[feature + '_count_dist'] = train[feature].map(train[feature].value_counts(dropna=False))\n",
    "    test[feature + '_count_dist'] = test[feature].map(test[feature].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cols = ['M1','M2','M3','M5','M6','M7','M8','M9']\n",
    "\n",
    "# Replace T with 1 and F with 0 before taking the sum\n",
    "for col in i_cols:\n",
    "    train[col] = train[col].apply(lambda x: 1 if x == 'T' else (0 if x == 'F' else np.nan))\n",
    "    test[col] = test[col].apply(lambda x: 1 if x == 'T' else (0 if x == 'F' else np.nan))\n",
    "\n",
    "for df in [train, test]:\n",
    "    df['M_sum'] = df[i_cols].sum(axis=1).astype(np.int8)\n",
    "    df['M_na'] = df[i_cols].isna().sum(axis=1).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET='isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Test different options for this\n",
    "# ## Test different options for this\n",
    "# # categorical_cols = train.select_dtypes('category').columns   => didn't work\n",
    "# for col in ['ProductCD','M4']:\n",
    "#     temp_dict = train.groupby([col])[TARGET].agg(['mean']).reset_index().rename(\n",
    "#                                                         columns={'mean': col+'_target_mean'})\n",
    "#     temp_dict.index = temp_dict[col].values\n",
    "#     temp_dict = temp_dict[col+'_target_mean'].to_dict()\n",
    "\n",
    "#     train[col+'_target_mean'] = train[col].map(temp_dict)\n",
    "#     test[col+'_target_mean']  = test[col].map(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test different options for this and see what we can do with it\n",
    "## Test different options for this\n",
    "train['uid'] = train['card1'].astype(str)+'_'+train['card2'].astype(str)\n",
    "test['uid'] = test['card1'].astype(str)+'_'+test['card2'].astype(str)\n",
    "\n",
    "train['uid2'] = train['uid'].astype(str)+'_'+train['card3'].astype(str)+'_'+train['card4'].astype(str)\n",
    "test['uid2'] = test['uid'].astype(str)+'_'+test['card3'].astype(str)+'_'+test['card4'].astype(str)\n",
    "\n",
    "train['uid3'] = train['uid2'].astype(str)+'_'+train['addr1'].astype(str)+'_'+train['addr2'].astype(str)\n",
    "test['uid3'] = test['uid2'].astype(str)+'_'+test['addr1'].astype(str)+'_'+test['addr2'].astype(str)\n",
    "\n",
    "\n",
    "# Check if the Transaction Amount is present in the other set (train vs. test) or not \n",
    "# In our dialog with a model we are telling to trust or not to these values   \n",
    "train['TransactionAmt_check']  = np.where(train['TransactionAmt'].isin(test['TransactionAmt']), 1, 0)\n",
    "train['ProductCD_check'] = np.where(train['ProductCD'].isin(test['ProductCD']), 1, 0)\n",
    "test['TransactionAmt_check']  = np.where(test['TransactionAmt'].isin(train['TransactionAmt']), 1, 0)\n",
    "test['ProductCD_check']  = np.where(test['ProductCD'].isin(train['ProductCD']), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test different options for this and DO A FUNC ? \n",
    "## Test different options for this \n",
    "\n",
    "i_cols = ['card1','card2','card3','card5','uid','uid2','uid3']\n",
    "\n",
    "for col in i_cols:\n",
    "    for agg_type in ['mean','std']:\n",
    "        new_col_name = col+'_TransactionAmt_'+agg_type\n",
    "        temp_df = pd.concat([train[[col, 'TransactionAmt']], test[[col,'TransactionAmt']]])\n",
    "        #temp_df['TransactionAmt'] = temp_df['TransactionAmt'].astype(int)\n",
    "        temp_df = temp_df.groupby([col])['TransactionAmt'].agg([agg_type]).reset_index().rename(\n",
    "                                                columns={agg_type: new_col_name})\n",
    "        \n",
    "        temp_df.index = list(temp_df[col])\n",
    "        temp_df = temp_df[new_col_name].to_dict()   \n",
    "    \n",
    "        train[new_col_name] = train[col].map(temp_df)\n",
    "        test[new_col_name]  = test[col].map(temp_df)\n",
    "           \n",
    "\n",
    "train['TransactionAmt_log'] = np.log1p(train['TransactionAmt'])\n",
    "test['TransactionAmt_log'] = np.log1p(test['TransactionAmt'])\n",
    "\n",
    "# Cell two (but it's more or less the same stuff so I put it here)\n",
    "for col in ['card1','card2','card3','card5','addr1','addr2',\n",
    "            'dist2','C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11',\n",
    "            'C12','C13','C14','TransactionAmt','D1','D2','D3','D4','D5','D6',\n",
    "            'D7','D8','D9','D10','D13','D14','D15','uid','uid2','uid3']:\n",
    "    for agg_type in ['mean','std']:\n",
    "        if (train[col].dtypes!='object'):\n",
    "            new_col_name = col+'_ProductCD_'+agg_type\n",
    "            temp_dict = train.groupby(['ProductCD'])[col].agg([agg_type]).reset_index().rename(columns={agg_type: new_col_name})\n",
    "            temp_dict.index = temp_dict[new_col_name].values\n",
    "            temp_dict = temp_dict[new_col_name].to_dict()\n",
    "        \n",
    "            train[new_col_name] = train[col].map(temp_dict)\n",
    "            test[new_col_name]  = test[col].map(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'P_emaildomain'\n",
    "r = 'R_emaildomain'\n",
    "uknown = 'email_not_provided'\n",
    "\n",
    "for df in [train, test]:\n",
    "    df[p] = df[p].astype(str)\n",
    "    df[p] = df[p].fillna(uknown)\n",
    "    df[r] = df[r].astype(str)\n",
    "    df[r] = df[r].fillna(uknown)\n",
    "    \n",
    "    # Check if P_emaildomain matches R_emaildomain\n",
    "    df['email_check'] = np.where((df[p]==df[r])&(df[p]!=uknown),1,0)\n",
    "\n",
    "    df[p+'_prefix'] = df[p].apply(lambda x: x.split('.')[0])\n",
    "    df[r+'_prefix'] = df[r].apply(lambda x: x.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFACTO\n",
    "# REFACTO\n",
    "\n",
    "for df in [train, test]:\n",
    "    for col in ['DeviceInfo', 'id_30', 'id_31']:\n",
    "        df[col] = df[col].astype(str).fillna('unknown_device').str.lower()\n",
    "        df[col+'_device'] = df[col].apply(lambda x: ''.join([i for i in x if i.isalpha()]))\n",
    "        df[col+'_version'] = df[col].apply(lambda x: ''.join([i for i in x if i.isnumeric()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could be done with and without test... \n",
    "########################### Freq encoding\n",
    "\n",
    "\n",
    "i_cols = ['card1','card2','card3','card5',\n",
    "          'C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14',\n",
    "          'D1','D2','D3','D4','D5','D6','D7','D8',\n",
    "          'addr1','addr2',\n",
    "          'dist1','dist2',\n",
    "          'P_emaildomain', 'R_emaildomain',\n",
    "          'DeviceInfo','DeviceInfo_device','DeviceInfo_version',\n",
    "          'id_30','id_30_device','id_30_version',\n",
    "          'id_31_device',\n",
    "          'id_33',\n",
    "          'uid','uid2','uid3',]\n",
    "\n",
    "for col in i_cols:\n",
    "    temp_df = pd.concat([train[[col]], test[[col]]])\n",
    "    fq_encode = temp_df[col].value_counts(dropna=False).to_dict()   \n",
    "    train[col+'_fq_enc'] = train[col].map(fq_encode)\n",
    "    test[col+'_fq_enc']  = test[col].map(fq_encode)\n",
    "    \n",
    "\n",
    "# Same stuff with other variables and a different naming... why ?\n",
    "for col in ['DT_M','DT_W','DT_D']:\n",
    "    temp_df = pd.concat([train[[col]], test[[col]]])\n",
    "    fq_encode = temp_df[col].value_counts().to_dict()\n",
    "            \n",
    "    train[col+'_total'] = train[col].map(fq_encode)\n",
    "    test[col+'_total']  = test[col].map(fq_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this DO? => frequency encoding of a mix between uid and periods\n",
    "## Test different options for this (different uids ?)\n",
    "## Test different options for this (different uids ?)\n",
    "\n",
    "periods = ['DT_M','DT_W','DT_D']\n",
    "i_cols = ['uid']\n",
    "for period in periods:\n",
    "    for col in i_cols:\n",
    "        new_column = col + '_' + period\n",
    "            \n",
    "        temp_df = pd.concat([train[[col,period]], test[[col,period]]])\n",
    "        temp_df[new_column] = temp_df[col].astype(str) + '_' + (temp_df[period]).astype(str)\n",
    "        fq_encode = temp_df[new_column].value_counts().to_dict()\n",
    "            \n",
    "        train[new_column] = (train[col].astype(str) + '_' + train[period].astype(str)).map(fq_encode)\n",
    "        test[new_column]  = (test[col].astype(str) + '_' + test[period].astype(str)).map(fq_encode)\n",
    "        \n",
    "        train[new_column] /= train[period+'_total']\n",
    "        test[new_column]  /= test[period+'_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_split(dataframe):\n",
    "    dataframe['device_name'] = dataframe['DeviceInfo'].str.split('/', expand=True)[0]\n",
    "    dataframe['device_version'] = dataframe['DeviceInfo'].str.split('/', expand=True)[1]\n",
    "\n",
    "    dataframe['OS_id_30'] = dataframe['id_30'].str.split(' ', expand=True)[0]\n",
    "    dataframe['version_id_30'] = dataframe['id_30'].str.split(' ', expand=True)[1]\n",
    "\n",
    "    dataframe['browser_id_31'] = dataframe['id_31'].str.split(' ', expand=True)[0]\n",
    "    dataframe['version_id_31'] = dataframe['id_31'].str.split(' ', expand=True)[1]\n",
    "\n",
    "    dataframe['screen_width'] = dataframe['id_33'].str.split('x', expand=True)[0]\n",
    "    dataframe['screen_height'] = dataframe['id_33'].str.split('x', expand=True)[1]\n",
    "\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('SM', na=False), 'device_name'] = 'Samsung'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('SAMSUNG', na=False), 'device_name'] = 'Samsung'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('GT-', na=False), 'device_name'] = 'Samsung'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Moto G', na=False), 'device_name'] = 'Motorola'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Moto', na=False), 'device_name'] = 'Motorola'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('moto', na=False), 'device_name'] = 'Motorola'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('LG-', na=False), 'device_name'] = 'LG'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('rv:', na=False), 'device_name'] = 'RV'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('HUAWEI', na=False), 'device_name'] = 'Huawei'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('ALE-', na=False), 'device_name'] = 'Huawei'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('-L', na=False), 'device_name'] = 'Huawei'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Blade', na=False), 'device_name'] = 'ZTE'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('BLADE', na=False), 'device_name'] = 'ZTE'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Linux', na=False), 'device_name'] = 'Linux'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('XT', na=False), 'device_name'] = 'Sony'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('HTC', na=False), 'device_name'] = 'HTC'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('ASUS', na=False), 'device_name'] = 'Asus'\n",
    "\n",
    "    dataframe.loc[dataframe.device_name.isin(dataframe.device_name.value_counts()[dataframe.device_name.value_counts() < 200].index), 'device_name'] = \"Others\"\n",
    "    dataframe['had_id'] = 1\n",
    "    gc.collect()\n",
    "    \n",
    "    return dataframe\n",
    "train=id_split(train)\n",
    "test=id_split(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['id_02_to_mean_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('mean')\n",
    "train['id_02_to_mean_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('mean')\n",
    "train['id_02_to_std_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('std')\n",
    "train['id_02_to_std_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "test['id_02_to_mean_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('mean')\n",
    "test['id_02_to_mean_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('mean')\n",
    "test['id_02_to_std_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('std')\n",
    "test['id_02_to_std_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "train['D15_to_mean_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('mean')\n",
    "train['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\n",
    "train['D15_to_std_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('std')\n",
    "train['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "test['D15_to_mean_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('mean')\n",
    "test['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\n",
    "test['D15_to_std_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('std')\n",
    "test['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "train['D15_to_mean_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('mean')\n",
    "train['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\n",
    "train['D15_to_std_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('std')\n",
    "train['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "test['D15_to_mean_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('mean')\n",
    "test['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\n",
    "test['D15_to_std_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('std')\n",
    "test['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New feature - decimal part of the transaction amount.\n",
    "train['TransactionAmt_decimal'] = ((train['TransactionAmt'] - train['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "test['TransactionAmt_decimal'] = ((test['TransactionAmt'] - test['TransactionAmt'].astype(int)) * 1000).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination of categorical variables\n",
    "for feature in ['id_02__id_20', 'id_02__D8', 'D11__DeviceInfo', 'DeviceInfo__P_emaildomain', 'P_emaildomain__C2', \n",
    "                'card2__dist1', 'card1__card5', 'card2__id_20', 'card5__P_emaildomain', 'addr1__card1',\n",
    "                'id_02__id_14','id_14__id_20','id_02__id_17','id_14__id_17','id_17__id_20','id_02__id_19','id_14__id_19','id_17__id_19',\n",
    "                'id_19__id_20'\n",
    "               ]:\n",
    "\n",
    "    f1, f2 = feature.split('__')\n",
    "    train[feature] = train[f1].astype(str) + '_' + train[f2].astype(str)\n",
    "    test[feature] = test[f1].astype(str) + '_' + test[f2].astype(str)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(train[feature].astype(str).values) + list(test[feature].astype(str).values))\n",
    "    train[feature] = le.transform(list(train[feature].astype(str).values))\n",
    "    test[feature] = le.transform(list(test[feature].astype(str).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in 'C3,C5,C9'.split(','): \n",
    "#         train[col+'_third_quartile'] = train.groupby('uid3')[col].transform(lambda x: x > x.quantile(0.75))\n",
    "#         test[col+'_third_quartile'] = test.groupby('uid3')[col].transform(lambda x: x > x.quantile(0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 639/640 [01:12<00:00,  9.20it/s]"
     ]
    }
   ],
   "source": [
    "## Test different options for this (with p-value and statistic changing)\n",
    "## Test different options for this \n",
    "\n",
    "def get_diff_columns(train_df, test_df, show_plots=True, show_all=False, threshold=0.01):\n",
    "    \"\"\"\"Use KS to estimate columns where distributions differ a lot from each other\"\"\"\n",
    "    numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    # Find the columns where the distributions are very different\n",
    "    diff_data = []\n",
    "    for col in tqdm(test_df.columns):\n",
    "        if (test_df[col].dtypes in numerics) and (col!='TransactionID'):\n",
    "            statistic, pvalue = ks_2samp(\n",
    "                train_df[col].values, \n",
    "                test_df[col].values\n",
    "            )\n",
    "            if pvalue == 0:\n",
    "                diff_data.append({'feature': col, 'p': np.round(pvalue, 5), 'statistic': np.round(np.abs(statistic), 2)})\n",
    "\n",
    "    # Put the differences into a dataframe\n",
    "    diff_df = pd.DataFrame(diff_data).sort_values(by='statistic', ascending=False)\n",
    "    return diff_df\n",
    "\n",
    "diff_df=get_diff_columns(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df[ diff_df['statistic'] > 0.15]['feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(diff_df[ diff_df['statistic'] > 0.15]['feature'].tolist(),axis=1)\n",
    "test=test.drop(diff_df[ diff_df['statistic'] > 0.15]['feature'].tolist(),axis=1)\n",
    "del(diff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "for col in list(train):\n",
    "    if train[col].dtype=='O':\n",
    "        train[col] = train[col].fillna('unseen_before_label')\n",
    "        test[col]  = test[col].fillna('unseen_before_label')\n",
    "        \n",
    "        train[col] = train[col].astype(str)\n",
    "        test[col] = test[col].astype(str)\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train[col])+list(test[col]))\n",
    "        train[col] = le.transform(train[col])\n",
    "        test[col]  = le.transform(test[col])\n",
    "        \n",
    "        train[col] = train[col].astype('category')\n",
    "        test[col] = test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_cols = [\n",
    "    'TransactionID','TransactionDT', # These columns are pure noise right now\n",
    "    TARGET,                          # Not target in features))\n",
    "    'uid','uid2','uid3',             # Our new client uID -> very noisy data\n",
    "    'bank_type',                     # Victims bank could differ by time\n",
    "    'DT','DT_M','DT_W','DT_D',       # Temporary Variables\n",
    "    'DT_hour','DT_day_week','DT_day',\n",
    "    'DT_D_total','DT_W_total','DT_M_total',\n",
    "    'id_30','id_31','id_33',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-31 23:58:51\n",
      "2018-07-01 00:00:24\n"
     ]
    }
   ],
   "source": [
    "features_columns = [col for col in list(train) if col not in rm_cols]\n",
    "\n",
    "# The June month drops entirely\n",
    "train['random_noise'] = np.random.randn(len(train))\n",
    "print(train['DT'].max())\n",
    "print(test['DT'].min())\n",
    "# So we need to get rid of April and keep May as validation set\n",
    "X_train = train[ train['DT'] <= '2018-03-31']\n",
    "y_train = X_train[TARGET]\n",
    "X_train = X_train[features_columns]\n",
    "X_valid = train[ (train['DT'] >= '2018-05-01')]\n",
    "y_valid = X_valid[TARGET]\n",
    "X_valid = X_valid[features_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 496,\n",
    "                    'max_depth':-1,\n",
    "                    'min_data_in_leaf':50,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':800,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':-1,\n",
    "                    'seed': 24,\n",
    "                    'early_stopping_rounds':100, \n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.962749\tvalid_1's auc: 0.896209\n",
      "[200]\ttraining's auc: 0.983521\tvalid_1's auc: 0.908402\n",
      "[300]\ttraining's auc: 0.994043\tvalid_1's auc: 0.915231\n",
      "[400]\ttraining's auc: 0.998058\tvalid_1's auc: 0.918607\n",
      "[500]\ttraining's auc: 0.999395\tvalid_1's auc: 0.91944\n",
      "[600]\ttraining's auc: 0.999822\tvalid_1's auc: 0.919751\n",
      "Early stopping, best iteration is:\n",
      "[667]\ttraining's auc: 0.999926\tvalid_1's auc: 0.919994\n"
     ]
    }
   ],
   "source": [
    "tr_data = lgb.Dataset(X_train, label=y_train)\n",
    "vl_data = lgb.Dataset(X_valid, label=y_valid)  \n",
    "        \n",
    "estimator = lgb.train(\n",
    "                lgb_params,\n",
    "                tr_data,\n",
    "                valid_sets = [tr_data, vl_data],\n",
    "                verbose_eval = 100)   \n",
    "\n",
    "#Early stopping, best iteration is:\n",
    "#[518]\ttraining's auc: 0.999265\tvalid_1's auc: 0.916453\n",
    "#Early stopping, best iteration is:\n",
    "#[661]\ttraining's auc: 0.999878\tvalid_1's auc: 0.915671\n",
    "\n",
    "# How much does is change when I keep a lot of V's ? \n",
    "#Early stopping, best iteration is:\n",
    "#[540]\ttraining's auc: 0.999628\tvalid_1's auc: 0.919858\n",
    "#[800]\ttraining's auc: 0.999987\tvalid_1's auc: 0.92052\n",
    "# Early stopping, best iteration is:\n",
    "# [689]\ttraining's auc: 0.999944\tvalid_1's auc: 0.92547\n",
    "\n",
    "#0.919613 vs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.960883\tvalid_1's auc: 0.898043\n",
      "[200]\ttraining's auc: 0.978829\tvalid_1's auc: 0.906967\n",
      "[300]\ttraining's auc: 0.989237\tvalid_1's auc: 0.911635\n",
      "[400]\ttraining's auc: 0.994657\tvalid_1's auc: 0.913522\n",
      "[500]\ttraining's auc: 0.997254\tvalid_1's auc: 0.914146\n",
      "[600]\ttraining's auc: 0.998503\tvalid_1's auc: 0.914502\n",
      "Early stopping, best iteration is:\n",
      "[585]\ttraining's auc: 0.998365\tvalid_1's auc: 0.914585\n"
     ]
    }
   ],
   "source": [
    "useful_vars = pd.read_csv('permut_imp_df.csv')\n",
    "usecols = useful_vars[ useful_vars['permut_importances'] > 0.05]['cols']\n",
    "usecols = [col for col in usecols if col in X_train.columns]\n",
    "tr_data = lgb.Dataset(X_train[usecols], label=y_train)\n",
    "vl_data = lgb.Dataset(X_valid[usecols], label=y_valid)  \n",
    "        \n",
    "estimator = lgb.train(\n",
    "                lgb_params,\n",
    "                tr_data,\n",
    "                valid_sets = [tr_data, vl_data],\n",
    "                verbose_eval = 100)   \n",
    "\n",
    "#Early stopping, best iteration is:\n",
    "#[518]\ttraining's auc: 0.999265\tvalid_1's auc: 0.916453\n",
    "#Early stopping, best iteration is:\n",
    "#[661]\ttraining's auc: 0.999878\tvalid_1's auc: 0.915671\n",
    "\n",
    "# How much does is change when I keep a lot of V's ? \n",
    "#Early stopping, best iteration is:\n",
    "#[540]\ttraining's auc: 0.999628\tvalid_1's auc: 0.919858\n",
    "#[800]\ttraining's auc: 0.999987\tvalid_1's auc: 0.92052\n",
    "# Early stopping, best iteration is:\n",
    "# [689]\ttraining's auc: 0.999944\tvalid_1's auc: 0.92547"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "72\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.98051\tvalid_1's auc: 0.910601\n",
      "[300]\ttraining's auc: 0.990435\tvalid_1's auc: 0.916149\n",
      "[400]\ttraining's auc: 0.995444\tvalid_1's auc: 0.918278\n",
      "[500]\ttraining's auc: 0.997777\tvalid_1's auc: 0.91928\n",
      "[600]\ttraining's auc: 0.998919\tvalid_1's auc: 0.919325\n",
      "[700]\ttraining's auc: 0.999444\tvalid_1's auc: 0.919396\n",
      "Early stopping, best iteration is:\n",
      "[670]\ttraining's auc: 0.999325\tvalid_1's auc: 0.919529\n"
     ]
    }
   ],
   "source": [
    "usecols = useful_vars[ useful_vars['permut_importances'] > 0.05]['cols'].tolist()\n",
    "print(len(usecols))\n",
    "for col in useful_vars[ useful_vars['permut_importances'] > 0.01]['cols'].tolist():\n",
    "    if col in X_train.columns and train[col].nunique() <= 50: #not so many split this var can make to overfit\n",
    "        usecols.append(col)\n",
    "usecols = list(set(usecols))\n",
    "usecols = [col for col in usecols if col in X_train.columns]\n",
    "print(len(usecols))\n",
    "tr_data = lgb.Dataset(X_train[usecols], label=y_train)\n",
    "vl_data = lgb.Dataset(X_valid[usecols], label=y_valid)  \n",
    "        \n",
    "estimator = lgb.train(\n",
    "                lgb_params,\n",
    "                tr_data,\n",
    "                valid_sets = [tr_data, vl_data],\n",
    "                verbose_eval = 100)   \n",
    "\n",
    "#Early stopping, best iteration is:\n",
    "#[518]\ttraining's auc: 0.999265\tvalid_1's auc: 0.916453\n",
    "#Early stopping, best iteration is:\n",
    "#[661]\ttraining's auc: 0.999878\tvalid_1's auc: 0.915671\n",
    "\n",
    "# How much does is change when I keep a lot of V's ? \n",
    "#Early stopping, best iteration is:\n",
    "#[540]\ttraining's auc: 0.999628\tvalid_1's auc: 0.919858\n",
    "#[800]\ttraining's auc: 0.999987\tvalid_1's auc: 0.92052\n",
    "# Early stopping, best iteration is:\n",
    "# [689]\ttraining's auc: 0.999944\tvalid_1's auc: 0.92547"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.954769\n",
      "[200]\ttraining's auc: 0.974852\n",
      "[300]\ttraining's auc: 0.985592\n",
      "[400]\ttraining's auc: 0.991455\n",
      "[500]\ttraining's auc: 0.994956\n",
      "[600]\ttraining's auc: 0.996976\n",
      "[700]\ttraining's auc: 0.998135\n",
      "[800]\ttraining's auc: 0.998812\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's auc: 0.998812\n"
     ]
    }
   ],
   "source": [
    "tr_data = lgb.Dataset(train[usecols], label=train[TARGET])\n",
    "estimator = lgb.train(\n",
    "                lgb_params,\n",
    "                tr_data,\n",
    "                valid_sets = [tr_data],\n",
    "                verbose_eval = 100)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = estimator.predict(test[usecols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission.csv')\n",
    "sub['isFraud'] = preds\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Kfold on valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "EPOCHS = 5\n",
    "kf = KFold(n_splits = EPOCHS, shuffle = False)\n",
    "y_preds = np.zeros(X_valid.shape[0])\n",
    "y_oof = np.zeros(X_train.shape[0])\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "rocs = []\n",
    "permut_importances = np.zeros(len(X_train.columns))\n",
    "\n",
    "for tr_idx, val_idx in kf.split(X_train, y_train):\n",
    " \n",
    "    X_tr, X_vl = X_train.iloc[tr_idx, :], X_train.iloc[val_idx, :]\n",
    "    y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    tr_data = lgb.Dataset(X_tr[usecols], label=y_tr)\n",
    "    vl_data = lgb.Dataset(X_vl[usecols], label=y_vl)  \n",
    "        \n",
    "    clf = lgb.train(\n",
    "                lgb_params,\n",
    "                tr_data,\n",
    "                valid_sets = [tr_data, vl_data],\n",
    "                verbose_eval = 100)\n",
    "    y_pred_train = clf.predict_proba(X_vl)[:,1]\n",
    "    y_oof[val_idx] = y_pred_train\n",
    "    print('train finished')\n",
    "    precision = precision_score(y_vl, (y_pred_train > 0.5).astype(int))\n",
    "    print('precision {}'.format(precision))\n",
    "    recall = recall_score(y_vl, (y_pred_train > 0.5).astype(int))\n",
    "    print('recall {}'.format(recall))\n",
    "    f1 = f1_score(y_vl, (y_pred_train > 0.5).astype(int))\n",
    "    print('f1_score {}'.format(f1))\n",
    "    roc = roc_auc_score(y_vl, y_pred_train)\n",
    "    print('ROC AUC {}'.format(roc))\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)\n",
    "    rocs.append(roc)\n",
    "    \n",
    "    \n",
    "    y_preds+= clf.predict_proba(X_valid)[:,1] / EPOCHS\n",
    "    \n",
    "    # feat_importance:\n",
    "    for i, col in enumerate(X_train.columns.tolist()):\n",
    "        save = X_train[col].copy()\n",
    "        valid_to_modify[col] = np.random.permutation(valid_to_modify[col])\n",
    "        \n",
    "        predict_permutation = clf.predict_proba(valid_to_modify)\n",
    "        score_after_permut = roc_auc_score(y_vl, predict_permutation[:,1])\n",
    "        perte = roc - score_after_permut\n",
    "        permut_importances[i] += perte / EPOCHS\n",
    "        valid_to_modify[col] = save\n",
    "    if (permut_importances == 0 ).all():\n",
    "        print('no change...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what do I need to do to maximize the score ? \n",
    "# -ensure with all that stuff the public LB keeps following the local valid\n",
    "# if yes, keep doing some FE, notably W_HOUR_CENTS\n",
    "# Ensemble multiple models (test if ensembling on X_train or X_subsample helps with valid as well)\n",
    "\n",
    "# What do I need to do to maximize robustness ?\n",
    "# do permutation importance on validation\n",
    "# do permutation importance on cross-validation\n",
    "# do multiple drop importance on undersampling\n",
    "# do k2s and train-test prediction \n",
    "# remove the ones that are dangerous"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
