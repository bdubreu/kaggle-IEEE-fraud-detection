{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%flake8_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import gc\n",
    "from time import time\n",
    "import datetime\n",
    "import multiprocessing\n",
    "import warnings\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from reduce_mem_usage import reduce_mem_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train_w_fe.csv')\n",
    "test = pd.read_csv('input/test_w_fe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove some cols and split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-31 23:58:51\n",
      "2018-07-01 00:00:24\n"
     ]
    }
   ],
   "source": [
    "rm_cols = [\n",
    "    'TransactionID', 'TransactionDT',  # These columns are pure noise right now\n",
    "    TARGET,                            # Not target in features))\n",
    "    'uid', 'uid2', 'uid3',             # Our new client uID -> very noisy data\n",
    "    'bank_type',                       # Victims bank could differ by time\n",
    "    'DT', 'DT_M', 'DT_W', 'DT_D',      # Temporary Variables\n",
    "    'DT_hour', 'DT_day_week', 'DT_day',\n",
    "    'DT_D_total', 'DT_W_total', 'DT_M_total',\n",
    "    'id_30', 'id_31', 'id_33',\n",
    "]\n",
    "\n",
    "features_columns = [col for col in list(train) if col not in rm_cols]\n",
    "\n",
    "# The June month drops entirely\n",
    "train['random_noise'] = np.random.randn(len(train))\n",
    "print(train['DT'].max())\n",
    "print(test['DT'].min())\n",
    "# So we need to get rid of April and keep May as validation set\n",
    "X_train = train[train['DT'] <= '2018-03-31']\n",
    "y_train = X_train[TARGET]\n",
    "X_train = X_train[features_columns]\n",
    "X_valid = train[(train['DT'] >= '2018-05-01')]\n",
    "y_valid = X_valid[TARGET]\n",
    "X_valid = X_valid[features_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_class = X_train[y_train == 1]\n",
    "neg_class = X_train[y_train == 0].sample(frac=0.1, random_state=42)\n",
    "\n",
    "X_subsample = pd.concat([pos_class, neg_class])\n",
    "X_subsample = X_subsample.sample(frac=1)  # quick way to shuffle\n",
    "y_subsample = y_train[X_subsample.index]\n",
    "assert len(X_subsample) == len(y_subsample)\n",
    "assert (X_subsample.index == y_subsample.index).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline reminder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "                    'objective': 'binary',\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'metric': 'auc',\n",
    "                    'n_jobs': -1,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'num_leaves': 496,\n",
    "                    'max_depth': -1,\n",
    "                    'min_data_in_leaf': 50,\n",
    "                    'tree_learner': 'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq': 1,\n",
    "                    'subsample': 0.7,\n",
    "                    'n_estimators': 800,\n",
    "                    'max_bin': 255,\n",
    "                    'verbose': -1,\n",
    "                    'seed': 24,\n",
    "                    'early_stopping_rounds': 100,\n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.964286\tvalid_1's auc: 0.89266\n",
      "[200]\ttraining's auc: 0.97975\tvalid_1's auc: 0.901452\n",
      "[300]\ttraining's auc: 0.990258\tvalid_1's auc: 0.908027\n",
      "[400]\ttraining's auc: 0.995959\tvalid_1's auc: 0.912937\n",
      "[500]\ttraining's auc: 0.998521\tvalid_1's auc: 0.91514\n",
      "[600]\ttraining's auc: 0.999532\tvalid_1's auc: 0.915683\n",
      "[700]\ttraining's auc: 0.999878\tvalid_1's auc: 0.91592\n",
      "[800]\ttraining's auc: 0.999974\tvalid_1's auc: 0.915932\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's auc: 0.999974\tvalid_1's auc: 0.915932\n"
     ]
    }
   ],
   "source": [
    "tr_data = lgb.Dataset(X_subsample, label=y_subsample)\n",
    "vl_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "estimator = lgb.train(\n",
    "                lgb_params,\n",
    "                tr_data,\n",
    "                valid_sets=[tr_data, vl_data],\n",
    "                verbose_eval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature idea: SUM_ID_NANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the id cols (more than 6 characters is a col engineered with id)\n",
    "id_cols = [col for col in X_subsample.columns if 'id' in col and len(col) < 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in id_cols:\n",
    "    X_subsample[col] = X_subsample[col].apply(lambda x: np.nan if x == 'nan' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subsample['id_nan_count'] = X_subsample[id_cols].isnull().sum(axis=1)\n",
    "X_valid['id_nan_count'] = X_valid[id_cols].isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.964076\tvalid_1's auc: 0.892608\n",
      "[200]\ttraining's auc: 0.979792\tvalid_1's auc: 0.901635\n",
      "[300]\ttraining's auc: 0.990203\tvalid_1's auc: 0.909133\n",
      "[400]\ttraining's auc: 0.995951\tvalid_1's auc: 0.913507\n",
      "[500]\ttraining's auc: 0.998506\tvalid_1's auc: 0.91507\n",
      "[600]\ttraining's auc: 0.999528\tvalid_1's auc: 0.916248\n",
      "[700]\ttraining's auc: 0.999874\tvalid_1's auc: 0.916457\n",
      "[800]\ttraining's auc: 0.999974\tvalid_1's auc: 0.916279\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttraining's auc: 0.999974\tvalid_1's auc: 0.916279\n"
     ]
    }
   ],
   "source": [
    "tr_data = lgb.Dataset(X_subsample, label=y_subsample)\n",
    "vl_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "estimator = lgb.train(\n",
    "                lgb_params,\n",
    "                tr_data,\n",
    "                valid_sets=[tr_data, vl_data],\n",
    "                verbose_eval=100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature idea: C1 third quartile\n",
    "is this C1 value in the top 25% of the C1 values FOR THIS UID ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to regroup some variables to find back the users\n",
    "X_subsample['uid'] = X_subsample['card1'].astype(str) + '_' + \\\n",
    "    X_subsample['card2'].astype(str)\n",
    "X_valid['uid'] = X_valid['card1'].astype(str) + '_' + \\\n",
    "    X_valid['card2'].astype(str)\n",
    "\n",
    "X_subsample['uid2'] = X_subsample['uid'].astype(str) + '_' + \\\n",
    "    X_subsample['card3'].astype(str) + '_' + X_subsample['card4'].astype(str)\n",
    "X_valid['uid2'] = X_valid['uid'].astype(str) + '_' + \\\n",
    "    X_valid['card3'].astype(str) + '_' + X_valid['card4'].astype(str)\n",
    "\n",
    "X_subsample['uid3'] = X_subsample['uid2'].astype(str) + '_' + \\\n",
    "    X_subsample['addr1'].astype(str) + '_' + X_subsample['addr2'].astype(str)\n",
    "X_valid['uid3'] = X_valid['uid2'].astype(str) + '_' + \\\n",
    "    X_valid['addr1'].astype(str) + '_' + X_valid['addr2'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subsample['C1_third_quartile'] = \\\n",
    "    X_subsample.groupby('uid3')['C1'].transform(lambda x: x > x.quantile(0.75))\n",
    "\n",
    "X_valid['C1_third_quartile'] = \\\n",
    "    X_valid.groupby('uid3')['C1'].transform(lambda x: x > x.quantile(0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.964592\tvalid_1's auc: 0.893758\n",
      "[200]\ttraining's auc: 0.979979\tvalid_1's auc: 0.902955\n",
      "[300]\ttraining's auc: 0.990349\tvalid_1's auc: 0.91026\n",
      "[400]\ttraining's auc: 0.995984\tvalid_1's auc: 0.914434\n",
      "[500]\ttraining's auc: 0.998529\tvalid_1's auc: 0.916136\n",
      "[600]\ttraining's auc: 0.99954\tvalid_1's auc: 0.916838\n",
      "[700]\ttraining's auc: 0.999878\tvalid_1's auc: 0.916692\n",
      "Early stopping, best iteration is:\n",
      "[634]\ttraining's auc: 0.999701\tvalid_1's auc: 0.916851\n"
     ]
    }
   ],
   "source": [
    "tr_data = lgb.Dataset(X_subsample.drop(['uid', 'uid2', 'uid3'], axis=1),\n",
    "                      label=y_subsample)\n",
    "vl_data = lgb.Dataset(X_valid.drop(['uid', 'uid2', 'uid3'], axis=1),\n",
    "                      label=y_valid)\n",
    "\n",
    "estimator = lgb.train(\n",
    "                lgb_params,\n",
    "                tr_data,\n",
    "                valid_sets=[tr_data, vl_data],\n",
    "                verbose_eval=100)\n",
    "\n",
    "#  0.914075 => 0.91819\n",
    "#  0.909696 => 0.919665"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test same idea for all C features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0305da9d8ebc4b5e8e80b660119d731c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 C1 0.916795425004353 True\n",
      "0.9 C1 0.9168320630409046 True\n",
      "0.75 C2 0.9176519936917615 True\n",
      "0.9 C2 0.9164476430240032 True\n",
      "0.75 C3 0.9168900372581565 True\n",
      "0.9 C3 0.9168900372581565 True\n",
      "0.75 C4 0.9164403794848331 True\n",
      "0.9 C4 0.9172590958209366 True\n",
      "0.75 C5 0.9170851657193969 True\n",
      "0.9 C5 0.9159894291740267 False\n",
      "0.75 C6 0.9170134764502352 True\n",
      "0.9 C6 0.9162104568085228 False\n",
      "0.75 C7 0.9164801613301332 True\n",
      "0.9 C7 0.9171530481490551 True\n",
      "0.75 C8 0.9170694243263033 True\n",
      "0.9 C8 0.9166573358125022 True\n",
      "0.75 C9 0.9165775933270917 True\n",
      "0.9 C9 0.9159102379726146 False\n",
      "0.75 C10 0.9163536565520356 True\n",
      "0.9 C10 0.9166560246505597 True\n",
      "0.75 C11 0.9169702192808092 True\n",
      "0.9 C11 0.9163046742237869 True\n",
      "0.75 C12 0.916674172323809 True\n",
      "0.9 C12 0.9169142378807141 True\n",
      "0.75 C13 0.9160665381608767 False\n",
      "0.9 C13 0.9167152020078896 True\n",
      "0.75 C14 0.9164115041229637 True\n",
      "0.9 C14 0.9173936836144182 True\n"
     ]
    }
   ],
   "source": [
    "def quantile_trans(x):\n",
    "    return x > x.quantile(decile)\n",
    "\n",
    "\n",
    "C_cols = [col for col in X_subsample.columns\n",
    "          if col.startswith('C') and '_' not in col]\n",
    "results_c_cols = {}\n",
    "for col in tqdm_notebook(C_cols):\n",
    "    for decile in [0.75, 0.9]:\n",
    "        X_subsample[col + '_third_quartile'] = \\\n",
    "            X_subsample.groupby('uid3')[col].transform(quantile_trans)\n",
    "        X_valid[col + '_third_quartile'] = \\\n",
    "            X_valid.groupby('uid3')[col].transform(quantile_trans)\n",
    "\n",
    "        uids = ['uid', 'uid2', 'uid3']\n",
    "        tr_data = lgb.Dataset(X_subsample.drop(uids, axis=1),\n",
    "                              label=y_subsample)\n",
    "        vl_data = lgb.Dataset(X_valid.drop(uids, axis=1),\n",
    "                              label=y_valid)\n",
    "\n",
    "        estimator3 = lgb.train(\n",
    "                    lgb_params,\n",
    "                    tr_data,\n",
    "                    valid_sets=[tr_data, vl_data],\n",
    "                    verbose_eval=0)\n",
    "\n",
    "        score_wo_feat = 0.916279\n",
    "        score_w_feat = estimator3.best_score['valid_1']['auc']\n",
    "        print(decile, col, score_w_feat, score_w_feat > score_wo_feat)\n",
    "        key = col + ' ' + str(decile)\n",
    "        results_c_cols[key] = score_w_feat - score_wo_feat\n",
    "        del(X_subsample[col+'_third_quartile'])\n",
    "        del(X_valid[col+'_third_quartile'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature idea: same general idea with TransactionAmt\n",
    "is this amount of transaction unusually high for this user ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "omg, omg2 = 1, 2\n",
    "del(omg, omg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = X_subsample.groupby('uid3')['TransactionAmt']\n",
    "X_subsample['AMT_95'] = group.transform(lambda x:  x > x.quantile(0.95))\n",
    "X_subsample['AMT_85'] = group.transform(lambda x:  x > x.quantile(0.85))\n",
    "X_subsample['AMT_75'] = group.transform(lambda x:  x > x.quantile(0.75))\n",
    "X_subsample['AMT_65'] = group.transform(lambda x:  x > x.quantile(0.65))\n",
    "X_subsample['AMT_55'] = group.transform(lambda x:  x > x.quantile(0.55))\n",
    "X_subsample['AMT_HH'] = X_subsample['AMT_55'] + X_subsample['AMT_65'] + \\\n",
    "    X_subsample['AMT_75'] + X_subsample['AMT_85'] + X_subsample['AMT_95']\n",
    "del(X_subsample['AMT_95'], X_subsample['AMT_85'], X_subsample['AMT_75'])\n",
    "del(X_subsample['AMT_65'], X_subsample['AMT_55'])\n",
    "\n",
    "group = X_valid.groupby('uid3')['TransactionAmt']\n",
    "X_valid['AMT_95'] = group.transform(lambda x:  x > x.quantile(0.95))\n",
    "X_valid['AMT_85'] = group.transform(lambda x:  x > x.quantile(0.85))\n",
    "X_valid['AMT_75'] = group.transform(lambda x:  x > x.quantile(0.75))\n",
    "X_valid['AMT_65'] = group.transform(lambda x:  x > x.quantile(0.65))\n",
    "X_valid['AMT_55'] = group.transform(lambda x:  x > x.quantile(0.55))\n",
    "X_valid['AMT_HH'] = X_valid['AMT_55'] + X_valid['AMT_65'] + \\\n",
    "    X_valid['AMT_75'] + X_valid['AMT_85'] + X_valid['AMT_95']\n",
    "del(X_valid['AMT_95'], X_valid['AMT_85'], X_valid['AMT_75'])\n",
    "del(X_valid['AMT_65'], X_valid['AMT_55'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.964472\tvalid_1's auc: 0.893614\n",
      "[200]\ttraining's auc: 0.979942\tvalid_1's auc: 0.901729\n",
      "[300]\ttraining's auc: 0.990367\tvalid_1's auc: 0.909175\n",
      "[400]\ttraining's auc: 0.995987\tvalid_1's auc: 0.913352\n",
      "[500]\ttraining's auc: 0.998531\tvalid_1's auc: 0.915003\n",
      "[600]\ttraining's auc: 0.99954\tvalid_1's auc: 0.915721\n",
      "[700]\ttraining's auc: 0.999879\tvalid_1's auc: 0.915657\n",
      "Early stopping, best iteration is:\n",
      "[631]\ttraining's auc: 0.999691\tvalid_1's auc: 0.915833\n"
     ]
    }
   ],
   "source": [
    "tr_data = lgb.Dataset(X_subsample.drop(uids, axis=1), label=y_subsample)\n",
    "vl_data = lgb.Dataset(X_valid.drop(uids, axis=1), label=y_valid)\n",
    "\n",
    "estimator2 = lgb.train(\n",
    "                lgb_params,\n",
    "                tr_data,\n",
    "                valid_sets=[tr_data, vl_data],\n",
    "                verbose_eval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse than without the var (score without the var is 0.9162, here 0.9158"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add more Target_encoding\n",
    "didn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permut_importances</th>\n",
       "      <th>cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020405</td>\n",
       "      <td>TransactionAmt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.502413</td>\n",
       "      <td>ProductCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>card1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.076115</td>\n",
       "      <td>card2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>card3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   permut_importances            cols\n",
       "0            0.020405  TransactionAmt\n",
       "1            0.502413       ProductCD\n",
       "2            0.000000           card1\n",
       "3            0.076115           card2\n",
       "4            0.000000           card3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permut_imp_df = pd.read_csv('permut_imp_df.csv')\n",
    "permut_imp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = permut_imp_df['permut_importances'] > 0.001\n",
    "useful_cols = permut_imp_df[mask]['cols'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = X_subsample.select_dtypes('category').columns\n",
    "X_subsample['isFraud'] = y_subsample\n",
    "for col in categorical_cols:\n",
    "    group = X_subsample.groupby([col])['isFraud']\n",
    "    temp_dict = group.agg(['mean']).reset_index().rename(\n",
    "        columns={'mean': col+'_target_mean'})\n",
    "    temp_dict.index = temp_dict[col].values\n",
    "    temp_dict = temp_dict[col+'_target_mean'].to_dict()\n",
    "\n",
    "    X_subsample[col+'_target_mean'] = X_subsample[col].map(temp_dict)\n",
    "    X_valid[col+'_target_mean'] = X_valid[col].map(temp_dict)\n",
    "del(X_subsample['isFraud'])\n",
    "\n",
    "# ProductCD\n",
    "# card1 - card6\n",
    "# addr1, addr2\n",
    "# Pemaildomain Remaildomain\n",
    "# M1 - M9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results worse than without those vars\n",
    "results_categories = {}\n",
    "for col in categorical_cols:\n",
    "    tr_data = lgb.Dataset(X_subsample[useful_cols +[col+'_target_mean']],\n",
    "                          label=y_subsample)\n",
    "    vl_data = lgb.Dataset(X_valid[useful_cols+[col+'_target_mean']],\n",
    "                          label=y_valid)  \n",
    "\n",
    "    estimator = lgb.train(\n",
    "                lgb_params,\n",
    "                tr_data,\n",
    "                valid_sets=[tr_data, vl_data],\n",
    "                verbose_eval=0)\n",
    "    score = estimator.best_score['valid_1']['auc']\n",
    "    print(col + '_target_mean', score)\n",
    "    results_categories[col + '_target_mean'] = score - 0.916279"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideés: \n",
    "# -revoir le uid avec addr1__addr2 + ALLcards\n",
    "# -revoir le uid avec addr1__addr2 + ALLcards + concatALLIDS\n",
    "# -Use D columns to figure out better ways to make sure the above makes sense :\n",
    "#    see https://www.kaggle.com/akasyanama13/eda-what-s-behind-d-features\n",
    "\n",
    "# that stuff: https://www.kaggle.com/kyakovlev/ieee-fe-with-some-eda\n",
    "# and here : https://www.kaggle.com/c/ieee-fraud-detection/discussion/108467#624394"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
