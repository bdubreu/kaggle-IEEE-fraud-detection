{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from time import time\n",
    "import datetime\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import roc_auc_score, auc\n",
    "warnings.simplefilter('ignore')\n",
    "sns.set()\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "local_test=True\n",
    "TARGET='isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_id=pd.read_csv('input/test_identity.csv')\n",
    "test_tr=pd.read_csv('input/test_transaction.csv')\n",
    "train_id =pd.read_csv('input/train_identity.csv')\n",
    "train_tr=pd.read_csv('input/train_transaction.csv')\n",
    "sub=pd.read_csv('input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.merge(train_tr, train_id, on='TransactionID', how='left')\n",
    "test = pd.merge(test_tr, test_id, on='TransactionID', how='left')\n",
    "\n",
    "del test_id, test_tr, train_id, train_tr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reduce_mem_usage(df, verbose=True):\n",
    "#     numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "#     start_mem = df.memory_usage().sum() / 1024**2    \n",
    "#     for col in tqdm_notebook(df.columns):\n",
    "#         col_type = df[col].dtypes\n",
    "#         if col_type in numerics:\n",
    "#             c_min = df[col].min()\n",
    "#             c_max = df[col].max()\n",
    "#             if str(col_type)[:3] == 'int':\n",
    "#                 if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "#                     df[col] = df[col].astype(np.int8)\n",
    "#                 elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "#                     df[col] = df[col].astype(np.int16)\n",
    "#                 elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "#                     df[col] = df[col].astype(np.int32)\n",
    "#                 elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "#                     df[col] = df[col].astype(np.int64)  \n",
    "#             else:\n",
    "#                 if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "#                     df[col] = df[col].astype(np.float16)\n",
    "#                 elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "#                     df[col] = df[col].astype(np.float32)\n",
    "#                 else:\n",
    "#                     df[col] = df[col].astype(np.float64)    \n",
    "#     end_mem = df.memory_usage().sum() / 1024**2\n",
    "#     if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "#     return df\n",
    "\n",
    "# train=reduce_mem_usage(train)\n",
    "# test=reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "card1 : 0\n",
      "card2 : 8933\n",
      "card3 : 1565\n",
      "card4 : 1577\n",
      "card5 : 4259\n",
      "card6 : 1571\n",
      "card1 : 0\n",
      "card2 : 4663\n",
      "card3 : 1565\n",
      "card4 : 1577\n",
      "card5 : 698\n",
      "card6 : 1571\n",
      "card1 : 0\n",
      "card2 : 4663\n",
      "card3 : 1565\n",
      "card4 : 1577\n",
      "card5 : 698\n",
      "card6 : 1565\n"
     ]
    }
   ],
   "source": [
    "i_cols = ['card1','card2','card3','card4','card5','card6']\n",
    "\n",
    "for col in i_cols:\n",
    "    print(col,':',train[col].isna().sum())\n",
    "\n",
    "########################### Let's play \"sudoku\" and fill nans in cards columns\n",
    "i_cols = ['TransactionID','card1','card2','card3','card4','card5','card6']\n",
    "\n",
    "full_df = pd.concat([train[i_cols], test[i_cols]])\n",
    "\n",
    "## I've used frequency encoding before so we have ints here\n",
    "## we will drop very rare cards\n",
    "full_df['card6'] = np.where(full_df['card6']==30, np.nan, full_df['card6'])\n",
    "full_df['card6'] = np.where(full_df['card6']==16, np.nan, full_df['card6'])\n",
    "\n",
    "\n",
    "i_cols = ['card2','card5']\n",
    "for col in i_cols:\n",
    "    temp_df = full_df.groupby(['card1',col])[col].agg(['count']).reset_index()\n",
    "    temp_df = temp_df.sort_values(by=['card1','count'], ascending=False).reset_index(drop=True)\n",
    "    del temp_df['count']\n",
    "    temp_df = temp_df.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "    temp_df.index = temp_df['card1'].values\n",
    "    temp_df = temp_df[col].to_dict()\n",
    "\n",
    "## We will find best match for nan values and fill with it\n",
    "for col in i_cols:\n",
    "    temp_df = full_df.groupby(['card1',col])[col].agg(['count']).reset_index()\n",
    "    temp_df = temp_df.sort_values(by=['card1','count'], ascending=False).reset_index(drop=True)\n",
    "    del temp_df['count']\n",
    "    temp_df = temp_df.drop_duplicates(subset='card1', keep='first').reset_index(drop=True)\n",
    "    temp_df.index = temp_df['card1'].values\n",
    "    temp_df = temp_df[col].to_dict()\n",
    "    full_df[col] = np.where(full_df[col].isna(), full_df['card1'].map(temp_df), full_df[col])\n",
    "    \n",
    "i_cols = ['card1','card2','card5']\n",
    "for col in i_cols:\n",
    "    train[col] = full_df[full_df['TransactionID'].isin(train['TransactionID'])][col].values\n",
    "    test[col] = full_df[full_df['TransactionID'].isin(test['TransactionID'])][col].values\n",
    "\n",
    "########################### Let's check how many nans left\n",
    "i_cols = ['card1','card2','card3','card4','card5','card6']\n",
    "\n",
    "for col in i_cols:\n",
    "    print(col,':',train[col].isna().sum())\n",
    "    \n",
    "    \n",
    "    \n",
    "##################################################################### SAME THING WITH CARD 6 and CARD4\n",
    "\n",
    "########################### Let's play \"sudoku\" and fill nans in cards columns\n",
    "i_cols = ['TransactionID','card1','card2','card3','card4','card5','card6']\n",
    "\n",
    "full_df = pd.concat([train[i_cols], test[i_cols]])\n",
    "\n",
    "## I've used frequency encoding before so we have ints here\n",
    "## we will drop very rare cards\n",
    "full_df['card6'] = np.where(full_df['card6']==30, np.nan, full_df['card6'])\n",
    "full_df['card6'] = np.where(full_df['card6']==16, np.nan, full_df['card6'])\n",
    "\n",
    "\n",
    "i_cols = ['card6']\n",
    "for col in i_cols:\n",
    "    temp_df = full_df.groupby(['card4',col])[col].agg(['count']).reset_index()\n",
    "    temp_df = temp_df.sort_values(by=['card4','count'], ascending=False).reset_index(drop=True)\n",
    "    del temp_df['count']\n",
    "    temp_df = temp_df.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "    temp_df.index = temp_df['card4'].values\n",
    "    temp_df = temp_df[col].to_dict()\n",
    "\n",
    "## We will find best match for nan values and fill with it\n",
    "for col in i_cols:\n",
    "    temp_df = full_df.groupby(['card4',col])[col].agg(['count']).reset_index()\n",
    "    temp_df = temp_df.sort_values(by=['card4','count'], ascending=False).reset_index(drop=True)\n",
    "    del temp_df['count']\n",
    "    temp_df = temp_df.drop_duplicates(subset='card4', keep='first').reset_index(drop=True)\n",
    "    temp_df.index = temp_df['card4'].values\n",
    "    temp_df = temp_df[col].to_dict()\n",
    "    full_df[col] = np.where(full_df[col].isna(), full_df['card4'].map(temp_df), full_df[col])\n",
    "    \n",
    "i_cols = ['card6']\n",
    "for col in i_cols:\n",
    "    train[col] = full_df[full_df['TransactionID'].isin(train['TransactionID'])][col].values\n",
    "    test[col] = full_df[full_df['TransactionID'].isin(test['TransactionID'])][col].values\n",
    "\n",
    "########################### Let's check how many nans left\n",
    "i_cols = ['card1','card2','card3','card4','card5','card6']\n",
    "\n",
    "for col in i_cols:\n",
    "    print(col,':',train[col].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'id_36']:\n",
    "    train[feature + '_count_full'] = train[feature].map(pd.concat([train[feature], test[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "    test[feature + '_count_full'] = test[feature].map(pd.concat([train[feature], test[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "# Encoding - count encoding separately for train and test\n",
    "for feature in ['id_01', 'id_31', 'id_33', 'id_36']:\n",
    "    train[feature + '_count_dist'] = train[feature].map(train[feature].value_counts(dropna=False))\n",
    "    test[feature + '_count_dist'] = test[feature].map(test[feature].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cols = ['M1','M2','M3','M5','M6','M7','M8','M9']\n",
    "\n",
    "# Replace T with 1 and F with 0 before taking the sum\n",
    "for col in i_cols:\n",
    "    train[col] = train[col].apply(lambda x: 1 if x == 'T' else (0 if x == 'F' else np.nan))\n",
    "    test[col] = test[col].apply(lambda x: 1 if x == 'T' else (0 if x == 'F' else np.nan))\n",
    "\n",
    "for df in [train, test]:\n",
    "    df['M_sum'] = df[i_cols].sum(axis=1).astype(np.int8)\n",
    "    df['M_na'] = df[i_cols].isna().sum(axis=1).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['ProductCD','M4']:\n",
    "    temp_dict = train.groupby([col])[TARGET].agg(['mean']).reset_index().rename(\n",
    "                                                        columns={'mean': col+'_target_mean'})\n",
    "    temp_dict.index = temp_dict[col].values\n",
    "    temp_dict = temp_dict[col+'_target_mean'].to_dict()\n",
    "\n",
    "    train[col+'_target_mean'] = train[col].map(temp_dict)\n",
    "    test[col+'_target_mean']  = test[col].map(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['uid'] = train['card1'].astype(str)+'_'+train['card2'].astype(str)\n",
    "test['uid'] = test['card1'].astype(str)+'_'+test['card2'].astype(str)\n",
    "\n",
    "train['uid2'] = train['uid'].astype(str)+'_'+train['card3'].astype(str)+'_'+train['card4'].astype(str)\n",
    "test['uid2'] = test['uid'].astype(str)+'_'+test['card3'].astype(str)+'_'+test['card4'].astype(str)\n",
    "\n",
    "train['uid3'] = train['uid2'].astype(str)+'_'+train['addr1'].astype(str)+'_'+train['addr2'].astype(str)\n",
    "test['uid3'] = test['uid2'].astype(str)+'_'+test['addr1'].astype(str)+'_'+test['addr2'].astype(str)\n",
    "\n",
    "# Check if the Transaction Amount is common or not (we can use freq encoding here)\n",
    "# In our dialog with a model we are telling to trust or not to these values   \n",
    "train['TransactionAmt_check']  = np.where(train['TransactionAmt'].isin(test['TransactionAmt']), 1, 0)\n",
    "train['ProductCD_check'] = np.where(train['ProductCD'].isin(test['ProductCD']), 1, 0)\n",
    "test['TransactionAmt_check']  = np.where(test['TransactionAmt'].isin(train['TransactionAmt']), 1, 0)\n",
    "test['ProductCD_check']  = np.where(test['ProductCD'].isin(train['ProductCD']), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cols = ['card1','card2','card3','card5','uid','uid2','uid3']\n",
    "\n",
    "for col in i_cols:\n",
    "    for agg_type in ['mean','std']:\n",
    "        new_col_name = col+'_TransactionAmt_'+agg_type\n",
    "        temp_df = pd.concat([train[[col, 'TransactionAmt']], test[[col,'TransactionAmt']]])\n",
    "        #temp_df['TransactionAmt'] = temp_df['TransactionAmt'].astype(int)\n",
    "        temp_df = temp_df.groupby([col])['TransactionAmt'].agg([agg_type]).reset_index().rename(\n",
    "                                                columns={agg_type: new_col_name})\n",
    "        \n",
    "        temp_df.index = list(temp_df[col])\n",
    "        temp_df = temp_df[new_col_name].to_dict()   \n",
    "    \n",
    "        train[new_col_name] = train[col].map(temp_df)\n",
    "        test[new_col_name]  = test[col].map(temp_df)\n",
    "           \n",
    "\n",
    "train['TransactionAmt'] = np.log1p(train['TransactionAmt'])\n",
    "test['TransactionAmt'] = np.log1p(test['TransactionAmt'])\n",
    "\n",
    "for col in ['card1','card2','card3','card4','card5','card6','addr1','addr2','dist2','C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C13','C14','TransactionAmt','D2','D8','D9'\n",
    "            ,'uid','uid2','uid3']:\n",
    "    for agg_type in ['mean','std']:\n",
    "        if (train[col].dtypes!='object'):\n",
    "            new_col_name = col+'_ProductCD_'+agg_type\n",
    "            temp_dict = train.groupby(['ProductCD'])[col].agg([agg_type]).reset_index().rename(\n",
    "                                                                columns={agg_type: new_col_name})\n",
    "            temp_dict.index = temp_dict[new_col_name].values\n",
    "            temp_dict = temp_dict[new_col_name].to_dict()\n",
    "        \n",
    "            train[new_col_name] = train[col].map(temp_dict)\n",
    "            test[new_col_name]  = test[col].map(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'P_emaildomain'\n",
    "r = 'R_emaildomain'\n",
    "uknown = 'email_not_provided'\n",
    "\n",
    "for df in [train, test]:\n",
    "    df[p] = df[p].fillna(uknown)\n",
    "    df[r] = df[r].fillna(uknown)\n",
    "    \n",
    "    # Check if P_emaildomain matches R_emaildomain\n",
    "    df['email_check'] = np.where((df[p]==df[r])&(df[p]!=uknown),1,0)\n",
    "\n",
    "    df[p+'_prefix'] = df[p].apply(lambda x: x.split('.')[0])\n",
    "    df[r+'_prefix'] = df[r].apply(lambda x: x.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    ########################### Device info\n",
    "    df['DeviceInfo'] = df['DeviceInfo'].fillna('unknown_device').str.lower()\n",
    "    df['DeviceInfo_device'] = df['DeviceInfo'].apply(lambda x: ''.join([i for i in x if i.isalpha()]))\n",
    "    df['DeviceInfo_version'] = df['DeviceInfo'].apply(lambda x: ''.join([i for i in x if i.isnumeric()]))\n",
    "    \n",
    "    ########################### Device info 2\n",
    "    df['id_30'] = df['id_30'].fillna('unknown_device').str.lower()\n",
    "    df['id_30_device'] = df['id_30'].apply(lambda x: ''.join([i for i in x if i.isalpha()]))\n",
    "    df['id_30_version'] = df['id_30'].apply(lambda x: ''.join([i for i in x if i.isnumeric()]))\n",
    "    \n",
    "    ########################### Browser\n",
    "    df['id_31'] = df['id_31'].fillna('unknown_device').str.lower()\n",
    "    df['id_31_device'] = df['id_31'].apply(lambda x: ''.join([i for i in x if i.isalpha()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_split(dataframe):\n",
    "    dataframe['device_name'] = dataframe['DeviceInfo'].str.split('/', expand=True)[0]\n",
    "    dataframe['device_version'] = dataframe['DeviceInfo'].str.split('/', expand=True)[1]\n",
    "\n",
    "    dataframe['OS_id_30'] = dataframe['id_30'].str.split(' ', expand=True)[0]\n",
    "    dataframe['version_id_30'] = dataframe['id_30'].str.split(' ', expand=True)[1]\n",
    "\n",
    "    dataframe['browser_id_31'] = dataframe['id_31'].str.split(' ', expand=True)[0]\n",
    "    dataframe['version_id_31'] = dataframe['id_31'].str.split(' ', expand=True)[1]\n",
    "\n",
    "    dataframe['screen_width'] = dataframe['id_33'].str.split('x', expand=True)[0]\n",
    "    dataframe['screen_height'] = dataframe['id_33'].str.split('x', expand=True)[1]\n",
    "\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('SM', na=False), 'device_name'] = 'Samsung'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('SAMSUNG', na=False), 'device_name'] = 'Samsung'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('GT-', na=False), 'device_name'] = 'Samsung'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Moto G', na=False), 'device_name'] = 'Motorola'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Moto', na=False), 'device_name'] = 'Motorola'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('moto', na=False), 'device_name'] = 'Motorola'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('LG-', na=False), 'device_name'] = 'LG'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('rv:', na=False), 'device_name'] = 'RV'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('HUAWEI', na=False), 'device_name'] = 'Huawei'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('ALE-', na=False), 'device_name'] = 'Huawei'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('-L', na=False), 'device_name'] = 'Huawei'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Blade', na=False), 'device_name'] = 'ZTE'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('BLADE', na=False), 'device_name'] = 'ZTE'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Linux', na=False), 'device_name'] = 'Linux'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('XT', na=False), 'device_name'] = 'Sony'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('HTC', na=False), 'device_name'] = 'HTC'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('ASUS', na=False), 'device_name'] = 'Asus'\n",
    "\n",
    "    dataframe.loc[dataframe.device_name.isin(dataframe.device_name.value_counts()[dataframe.device_name.value_counts() < 200].index), 'device_name'] = \"Others\"\n",
    "    dataframe['had_id'] = 1\n",
    "    gc.collect()\n",
    "    \n",
    "    return dataframe\n",
    "train=id_split(train)\n",
    "test=id_split(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['id_02_to_mean_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('mean')\n",
    "train['id_02_to_mean_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('mean')\n",
    "train['id_02_to_std_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('std')\n",
    "train['id_02_to_std_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "test['id_02_to_mean_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('mean')\n",
    "test['id_02_to_mean_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('mean')\n",
    "test['id_02_to_std_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('std')\n",
    "test['id_02_to_std_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "train['D15_to_mean_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('mean')\n",
    "train['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\n",
    "train['D15_to_std_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('std')\n",
    "train['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "test['D15_to_mean_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('mean')\n",
    "test['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\n",
    "test['D15_to_std_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('std')\n",
    "test['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "train['D15_to_mean_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('mean')\n",
    "train['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\n",
    "train['D15_to_std_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('std')\n",
    "train['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "test['D15_to_mean_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('mean')\n",
    "test['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\n",
    "test['D15_to_std_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('std')\n",
    "test['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TransactionAmt_Log'] = np.log(train['TransactionAmt'])\n",
    "test['TransactionAmt_Log'] = np.log(test['TransactionAmt'])\n",
    "\n",
    "# New feature - decimal part of the transaction amount.\n",
    "train['TransactionAmt_decimal'] = ((train['TransactionAmt'] - train['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "test['TransactionAmt_decimal'] = ((test['TransactionAmt'] - test['TransactionAmt'].astype(int)) * 1000).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['id_02__id_20', 'id_02__D8', 'D11__DeviceInfo', 'DeviceInfo__P_emaildomain', 'P_emaildomain__C2', \n",
    "                'card2__dist1', 'card1__card5', 'card2__id_20', 'card5__P_emaildomain', 'addr1__card1',\n",
    "                'id_02__id_14','id_14__id_20','id_02__id_17','id_14__id_17','id_17__id_20','id_02__id_19','id_14__id_19','id_17__id_19',\n",
    "                'id_19__id_20'\n",
    "               ]:\n",
    "\n",
    "    f1, f2 = feature.split('__')\n",
    "    train[feature] = train[f1].astype(str) + '_' + train[f2].astype(str)\n",
    "    test[feature] = test[f1].astype(str) + '_' + test[f2].astype(str)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(train[feature].astype(str).values) + list(test[feature].astype(str).values))\n",
    "    train[feature] = le.transform(list(train[feature].astype(str).values))\n",
    "    test[feature] = le.transform(list(test[feature].astype(str).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 563/563 [03:16<00:00,  2.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# def get_diff_columns(train_df, test_df, show_plots=True, show_all=False, threshold=0.01):\n",
    "#     \"\"\"\"Use KS to estimate columns where distributions differ a lot from each other\"\"\"\n",
    "#     #Kolmogorov–Smirnov test\n",
    "#     diff_data = []\n",
    "#     for col in tqdm(test_df.columns):\n",
    "#         if (test_df[col].dtypes!='object' and col!='TransactionID'and col!='DT'):\n",
    "#             statistic, pvalue = ks_2samp(\n",
    "#                 train_df[col].values, \n",
    "#                 test_df[col].values\n",
    "#             )\n",
    "#             if pvalue == 0 and statistic >0.15:\n",
    "#                 diff_data.append({'feature': col, 'p': np.round(pvalue, 5), 'statistic': np.round(np.abs(statistic), 2)})\n",
    "\n",
    "#     diff_df = pd.DataFrame(diff_data).sort_values(by='statistic', ascending=False)\n",
    "#     return diff_df\n",
    "\n",
    "# diff_df=get_diff_columns(train,test)\n",
    "# diff_df.to_csv('diff_df.csv', index=False)\n",
    "\n",
    "diff_df = pd.read_csv('diff_df.csv')\n",
    "\n",
    "train=train.drop(diff_df['feature'],axis=1)\n",
    "test=test.drop(diff_df['feature'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop=pd.read_csv('to_drop.csv')\n",
    "train=train.drop(to_drop['Feature'],axis=1,errors='ignore')\n",
    "test=test.drop(to_drop['Feature'],axis=1,errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_na=[]\n",
    "for col in train.columns:\n",
    "    na=train[col].isnull().sum()\n",
    "    if (na>len(train)*0.9):\n",
    "        to_drop_na.append(col)\n",
    "        \n",
    "train=train.drop(to_drop_na,axis=1)\n",
    "test=test.drop(to_drop_na,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 301/301 [00:29<00:00, 10.20it/s]\n"
     ]
    }
   ],
   "source": [
    "list_cols = []\n",
    "for col in tqdm(test.columns):\n",
    "  \n",
    "    if (col.startswith(\"V\")==False) and col != 'TransactionID':\n",
    "        \n",
    "        #temp_df = pd.concat([train[[col]], test[[col]]])\n",
    "        fq_encode = train[col].value_counts(dropna=False).to_dict()   \n",
    "        train[col+'_fq_enc'] = train[col].map(fq_encode)\n",
    "        test[col+'_fq_enc']  = test[col].map(fq_encode)\n",
    "    else:\n",
    "        list_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea: remove fq_enc if more than 100 categories\n",
    "fq_uniques = list()\n",
    "for col in train.columns:\n",
    "    if '_fq_enc' in col:\n",
    "        fq_uniques.append(train[col].nunique())\n",
    "pd.Series(np.array(fq_uniques)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    if train[col].dtype=='O':\n",
    "        train[col] = train[col].fillna('unseen_before_label')\n",
    "        test[col]  = test[col].fillna('unseen_before_label')\n",
    "        \n",
    "        train[col] = train[col].astype(str)\n",
    "        test[col] = test[col].astype(str)\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train[col])+list(test[col]))\n",
    "        train[col] = le.transform(train[col])\n",
    "        test[col]  = le.transform(test[col])\n",
    "        \n",
    "        train[col] = train[col].astype('category')\n",
    "        test[col] = test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_cols = [col for col in train.columns if col.startswith('C') and '_' not in col]\n",
    "# for col in C_cols: \n",
    "#     train[col+'_third_quartile'] = train.groupby('uid3')[col].transform(lambda x: x > x.quantile(0.75))\n",
    "#     test[col+'_third_quartile'] = test.groupby('uid3')[col].transform(lambda x: x > x.quantile(0.75))\n",
    "    \n",
    "# quartile_cols = [col for col in train.columns if col.endswith('quartile')]\n",
    "# train[['TransactionID']+quartile_cols].to_csv('trainquartiles.csv', index=False)\n",
    "# test[['TransactionID']+quartile_cols].to_csv('testquartiles.csv', index=False)\n",
    "train_quartiles = pd.read_csv('trainquartiles.csv')\n",
    "train = pd.merge(train, train_quartiles, on='TransactionID')\n",
    "test_quartiles = pd.read_csv('trainquartiles.csv')\n",
    "test = pd.merge(test, test_quartiles, on='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = [col for col in train.columns if 'id' in col and len(col) == 5]\n",
    "train['id_nan_count'] = train[id_cols].isnull().sum(axis=1)\n",
    "test['id_nan_count'] = test[id_cols].isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_cols = [\n",
    "    'TransactionID','TransactionDT', # These columns are pure noise right now\n",
    "    TARGET,                          # Not target in features))\n",
    "    'uid','uid2','uid3',             # Our new client uID -> very noisy data\n",
    "    'bank_type',                     # Victims bank could differ by time\n",
    "     'DT','DT_M','DT_W','DT_D',       # Temporary Variables\n",
    "    'DT_hour','DT_day_week','DT_day',\n",
    "    'DT_D_total','DT_W_total','DT_M_total',\n",
    "    'id_30','id_31','id_33',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permut_imp(model, vl_x, vl_y):\n",
    "    permutation_importances = {}\n",
    "    base_roc = roc_auc_score(vl_y, model.predict())\n",
    "    for col in features_columns:\n",
    "        save = vl_x[col].copy()\n",
    "        dtype = X_valid[col].dtype\n",
    "        vl_x[col] = np.random.permutation(vl_x[col])\n",
    "        X_valid[col] = vl_x[col].astype(dtype)\n",
    "\n",
    "        predict_permutation = model.predict(vl_x)\n",
    "        score_after_permut = roc_auc_score(vl_y, predict_permutation)\n",
    "        \n",
    "        perte = base_roc - score_after_permut\n",
    "        permut_importances[col] = perte * 100 \n",
    "        X_valid[col] = save\n",
    "        \n",
    "        return permut_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "def make_predictions_lgb(tr_df, tt_df, features_columns, target, lgb_params, NFOLDS=2):\n",
    "    folds = KFold(n_splits=NFOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "    X,y = tr_df[features_columns], tr_df[target]    \n",
    "    P = tt_df[features_columns] \n",
    "    \n",
    "        \n",
    "    predictions = np.zeros(len(sub))\n",
    "    permut_imp_allfolds = []\n",
    "    \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "        print('Fold:',fold_)\n",
    "        tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx]\n",
    "        vl_x, vl_y = X.iloc[val_idx,:], y[val_idx]\n",
    "            \n",
    "        print(len(tr_x),len(vl_x))\n",
    "        tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    \n",
    "        vl_data = lgb.Dataset(vl_x, label=vl_y)  \n",
    "    \n",
    "        estimator = lgb.train(\n",
    "            lgb_params,\n",
    "            tr_data,\n",
    "            valid_sets = [tr_data, vl_data],\n",
    "            verbose_eval = 200,\n",
    "        )   \n",
    "        \n",
    "        pp_p = estimator.predict(P)\n",
    "        predictions += pp_p/NFOLDS\n",
    "        \n",
    "        permut_imp_fold = permut_imp(estimator, vl_x, vl_y)\n",
    "        permut_imp_allfolds.append(permut_imp_fold)\n",
    "        \n",
    "        del tr_x, tr_y, vl_x, vl_y, tr_data, vl_data\n",
    "        gc.collect()\n",
    "\n",
    "    tt_df['prediction'] = predictions\n",
    "            \n",
    "    \n",
    "    return estimator,tt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns = [col for col in list(train) if col not in rm_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "506177 84363\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.960897\tvalid_1's auc: 0.94032\n",
      "[400]\ttraining's auc: 0.984326\tvalid_1's auc: 0.955628\n",
      "[600]\ttraining's auc: 0.994611\tvalid_1's auc: 0.965867\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 496,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':800,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':-1,\n",
    "                    'seed': 24,\n",
    "                    'early_stopping_rounds':100, \n",
    "                } \n",
    "\n",
    "lgb_params['learning_rate'] = 0.005\n",
    "lgb_params['n_estimators'] = 1800\n",
    "lgb_params['early_stopping_rounds'] = 100    \n",
    "clf,test_predictions = make_predictions_lgb(train, test, features_columns, TARGET, lgb_params, NFOLDS=7)\n",
    "#fold 2: 10h26-> 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions['isFraud'] = test_predictions['prediction']\n",
    "test_predictions['TransactionID']=test['TransactionID']\n",
    "test_predictions[['TransactionID','isFraud']].to_csv('submission.csv', index=False)\n",
    "\n",
    "# PLB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "11b181fb3d124359b8256288f78362bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3510f901be694af3bc66748c671b07bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_11b181fb3d124359b8256288f78362bc",
       "max": 433,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_da33b106911048b1aad2b4b4f36accaf",
       "value": 433
      }
     },
     "39875ca5aa754d109b9cbc5d2a43f3f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7ff237c4d1974c1e9b78b0564d89a9d8",
        "IPY_MODEL_6dc08f797c5c4fd09418e20acacf072c"
       ],
       "layout": "IPY_MODEL_afe3769ed6014f10890eadda09bf7ce9"
      }
     },
     "49218ce045de4f7693228b2e74ace8cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "573649973b924da99a48f96ff288bf2d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6dc08f797c5c4fd09418e20acacf072c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_573649973b924da99a48f96ff288bf2d",
       "placeholder": "​",
       "style": "IPY_MODEL_b5f67403541a4447b5101c55b022b171",
       "value": "100% 434/434 [01:35&lt;00:00,  4.57it/s]"
      }
     },
     "7ff237c4d1974c1e9b78b0564d89a9d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8b4e0157dfec458a805ed7334b8f3161",
       "max": 434,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f5e83a655b794fccb6e2eb8664acac73",
       "value": 434
      }
     },
     "8b4e0157dfec458a805ed7334b8f3161": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "954b390512004373b8d5167bd621e23b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "996f5049a23b4e5d951a51e5d5a22b5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_afca695cfc45480bbdf5d5639e08e260",
       "placeholder": "​",
       "style": "IPY_MODEL_49218ce045de4f7693228b2e74ace8cd",
       "value": "100% 433/433 [01:26&lt;00:00,  5.03it/s]"
      }
     },
     "a9cf05010b5c47abb923d768740db39e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3510f901be694af3bc66748c671b07bb",
        "IPY_MODEL_996f5049a23b4e5d951a51e5d5a22b5b"
       ],
       "layout": "IPY_MODEL_954b390512004373b8d5167bd621e23b"
      }
     },
     "afca695cfc45480bbdf5d5639e08e260": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "afe3769ed6014f10890eadda09bf7ce9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b5f67403541a4447b5101c55b022b171": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "da33b106911048b1aad2b4b4f36accaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f5e83a655b794fccb6e2eb8664acac73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
